---
layout: post
title:  "Thinking, Fast and Slow"
authors: Daniel Kahneman
tags: [16]
---

## Concepts

1. Law of least effort
1. Flow state
1. Working memory
1. Falling into easier defaults
1. Repetition and falsehood
1. Availability cascade
1. Bias for speaking first
1. Cognitive ease
1. Base rate neglect
1. Conjunction fallacy
1. Representativeness
1. Regression to the mean
1. Over confidence
1. Intuition
1. Narrative fallacies
1. Halo effect
1. Outcome bias
1. Illusion of skill
1. Planning Fallacy
1. Media profile acclaim performance
1. Pre-mortem
1. Loss aversion
1. Diminishing marginal utility
1. Small probabilities
1. Possibility Effect
1. Framing effect: Opt-in or Opt-out by default
1. Experience self vs Remembering self
1. Duration neglect
1. Peak-end rule
1. Phenomenon anchoring

## General

Pleasure in the journey

> The pleasure we found in working together **made us exceptionally patient**; it is **much easier to strive for perfection** when you are never bored.

Systematic errors in our minds are due to how our cognition works

> We **documented systematic errors in the thinking of normal people**, and we traced these errors to the **design of the machinery of cognition** rather than to the corruption of thought by emotion.

The field of heuristic and biases

> the ideas of heuristics and biases have been used productively in many fields, including **medical diagnosis, legal judgment, intelligence analysis, philosophy, finance, statistics, and military strategy**.

Relative importance == retrieval from memory

> People **tend to assess the relative importance of issues by the ease with which they are retrieved from memory** — and this is largely determined by the extent of **coverage in the media**. Frequently mentioned topics populate the mind even as others slip away from awareness. In turn, what the media choose to report corresponds to their view of what is currently on the public’s mind. It is no accident that authoritarian regimes exert substantial pressure on independent media.

Luck plays a large

> A recurrent theme of this book is that **luck plays a large role in every story of success**; it is almost always easy to identify a small change in the story that would have turned a remarkable achievement into a mediocre outcome. Our story was no exception.

What is intuition?

> The psychology of accurate intuition involves no magic. Perhaps the best short statement of it is by the great Herbert Simon, who studied chess masters and showed that **after thousands of hours of practice they come to see the pieces on the board differently from the rest of us**. You can feel Simon’s impatience with the mythologizing of expert intuition when he writes: “The situation has provided a cue; this cue has given the expert access to information stored in memory, and the information provides the answer. **Intuition is nothing more and nothing less than recognition.**”

How does system 1 and 2 work together?

> In the picture that emerges from recent research, the **intuitive System 1 is more influential** than your experience tells you, and it is the secret author of many of the choices and judgments you make. Most of this book is about the workings of System 1 and the mutual influences between it and System 2.

Overconfidence in understanding the world

> a puzzling limitation of our mind: our excessive confidence in what we believe we know, and our apparent inability to acknowledge the full extent of our ignorance and the uncertainty of the world we live in. **We are prone to overestimate how much we understand about the world and to underestimate the role of chance in events.** Overconfidence is fed by the **illusory certainty of hindsight**.

## System 1 and System 2

Automatic and effortful

> System 1 operates **automatically and quickly**, with little or no effort and no sense of voluntary control. System 2 **allocates attention to the effortful mental activities that demand it**, including complex computations.

Feeling and intuitions

> System 1 continuously generates suggestions for System 2: **impressions, intuitions, intentions, and feelings**. If endorsed by System 2, impressions and intuitions turn into beliefs, and **impulses turn into voluntary actions**. When all goes smoothly, which is most of the time, System 2 adopts the suggestions of System 1 with little or no modification.

System 1's goodness

> System 1 is generally very good at what it does: its **models of familiar situations are accurate**, its short-term predictions are usually accurate as well, and its initial reactions to challenges are swift and generally appropriate. **System 1 has biases, however**, systematic errors that it is prone to make in specified circumstances.

You cannot always turn on System 2

> Even when cues to likely errors are available, errors can be prevented only by the enhanced monitoring and effortful activity of System 2. As a way to live your life, however, **continuous vigilance is not necessarily good, and it is certainly impractical**.

Naming

> Why call them System 1 and System 2 rather than the more descriptive “automatic system” and “effortful system”? The reason is simple: “Automatic system” takes longer to say than “System 1” and therefore takes more space in your working memory. This matters, because anything that occupies your working memory reduces your ability to think.

How System 1 has developed

> The sophisticated allocation of attention has been honed by a long evolutionary history. **Orienting and responding quickly to the gravest threats** or most promising opportunities improved the chance of survival, and this capability is certainly not restricted to humans. **Even in modern humans, System 1 takes over in emergencies and assigns total priority to self-protective actions.**

Dealing with options

> System 2 is the only one that can follow rules, **compare objects on several attributes, and make deliberate choices between options**. The automatic System 1 does not have these capabilities. System 1 detects simple relations

Impulse and intuition vs reasoning and caution

> System 1 is impulsive and intuitive; System 2 is capable of reasoning, and it is cautious, but at least for some people it is also lazy.

Priming

> You do not believe that these results apply to you because they correspond to nothing in your subjective experience. But your subjective experience consists largely of the story that your System 2 tells itself about what is going on. Priming phenomena arise in System 1, and you have no conscious access to them.

New and old

> But there were questions where no good answer came to mind, where all I had to go by was cognitive ease. If the answer felt familiar, I assumed that it was probably true. If it looked new (or improbably extreme), I rejected it. The **impression of familiarity is produced by System 1**, and System 2 relies on that impression for a true/false judgment.

Cause-and-Effect from sequences

> Experiments have shown that six-month-old infants **see the sequence of events as a cause-effect scenario**, and they indicate surprise when the sequence is altered. We are evidently ready from birth to have impressions of causality, which do not depend on reasoning about patterns of causation. They are products of System 1.

Certainty vs doubt

> System 1 **does not keep track of alternatives that it rejects**, or even of the fact that there were alternatives. Conscious doubt is not in the repertoire of System 1; it **requires maintaining incompatible interpretations in mind at the same time, which demands mental effort**. Uncertainty and doubt are the domain of System 2.

Coherence and a story

> The measure of success for System 1 is the **coherence of the story it manages to create**. The amount and quality of the data on which the story is based are largely irrelevant. When information is scarce, which is a common occurrence, System 1 **operates as a machine for jumping to conclusions**.

Self-correcting System 2

> in many other examples of the interplay between the two systems, it appeared that **System 2 is ultimately in charge, with the ability to resist the suggestions of System 1, slow things down**, and impose logical analysis. Self-criticism is one of the functions of System 2. In the context of attitudes, however, System 2 is more of an apologist for the emotions of System 1 than a critic of those emotions—**an endorser rather than an enforcer**.

Emotion is disproportionate to the probability

> System 2 may “know” that the probability is low, but this knowledge does not eliminate the self-generated discomfort and the wish to avoid it. System 1 cannot be turned off. The **emotion is not only disproportionate to the probability, it is also insensitive to the exact level of probability**.

Mortality and Survival

> But System 1, as we have gotten to know it, is rarely indifferent to emotional words: mortality is bad, survival is good, and 90% survival sounds encouraging whereas 10% mortality is frightening.

Laziness of System 2

> Unlike other framing effects that have been traced to features of System 1, the organ donation effect is best explained by the **laziness of System 2**. People will check the box if they have already decided what they wish to do. If they are unprepared for the question, they have to make the effort of thinking whether they want to check the box.

Remembering self and duration neglect

> The remembering self is a construction of System 2. However, the distinctive features of the way it evaluates episodes and lives are characteristics of our memory. **Duration neglect and the peak-end rule originate in System 1** and do not necessarily correspond to the values of System 2. We believe that duration is important, but our memory tells us it is not. The **rules that govern the evaluation of the past are poor guides for decision making**, because time does matter. The central fact of our existence is that time is the ultimate finite resource, but the remembering self ignores that reality.

Skilled intuition

> System 1 registers the cognitive ease with which it processes information, but it does not generate a warning signal when it becomes unreliable. Intuitive answers come to mind quickly and confidently, whether they originate from skills or from heuristics. There is no simple way for System 2 to distinguish between a skilled and a heuristic response. Its only recourse is to slow down and attempt to construct an answer on its own, which it is reluctant to do because it is indolent.

Slow down, ask for reinforcement

> The way to block errors that originate in System 1 is simple in principle: **recognize the signs that you are in a cognitive minefield, slow down, and ask for reinforcement from System 2**. This is how you will proceed when you next encounter the Müller-Lyer illusion.

## Counter-intuitive

Learning to observe our own mistakes

> The best we can do is a compromise: **learn to recognize situations in which mistakes are likely** and try harder to avoid significant mistakes when the stakes are high. The premise of this book is that it is **easier to recognize other people’s mistakes than our own**.

Talent meaning

> Studies of the brain have shown that the **pattern of activity associated with an action changes as skill increases, with fewer brain regions involved**. Talent has similar effects. Highly intelligent individuals need less effort to solve the same problems, as indicated by both pupil size and brain activity.

Law of least effort

> A general “law of least effort” applies to cognitive as well as physical exertion. The law asserts that if there are several ways of achieving the same goal, **people will eventually gravitate to the least demanding course of action**.

We are all lazy

> In the economy of action, effort is a cost, and the **acquisition of skill is driven by the balance of benefits and costs**. Laziness is built deep into our nature.

Working memory

> Modern tests of working memory require the individual to **switch repeatedly between two demanding tasks**, retaining the results of one operation while performing the other. People who do well on these tests tend to do well on tests of general intelligence. However, the **ability to control attention is not simply a measure of intelligence**;

Flow state

> The psychologist Mihaly Csikszentmihalyi (pronounced six-cent-mihaly) has done more than anyone else to study this state of effortless attending, and the name he proposed for it, flow, has become part of the language. People who experience flow describe it as “a **state of effortless concentration so deep that they lose their sense of time**, of themselves, of their problems,” and their descriptions of the joy of that state are so compelling that Csikszentmihalyi has called it an “optimal experience.”

Don't focus too much on your performance

> The self-control of morning people is impaired at night; the reverse is true of night people. **Too much concern about how well one is doing in a task sometimes disrupts performance** by loading short-term memory with pointless anxious thoughts.

Beware of self-control

> Baumeister’s group has repeatedly found that **an effort of will or self-control is tiring**; if you have had to force yourself to do something, you are less willing or **less able to exert self-control when the next challenge comes around**. The phenomenon has been named **ego depletion**.

Perk up your performance with pleasant things

> On the other hand, the glucose drinkers were not depleted. **Restoring the level of available sugar in the brain had prevented the deterioration of performance.** It will take some time and much further research to establish whether the tasks that cause glucose-depletion also cause the momentary arousal that is reflected in increases of pupil size and heart rate.

Beware of falling into easier defaults

> The best possible account of the data provides bad news: **tired and hungry judges tend to fall back on the easier default** position of denying requests for parole. Both **fatigue and hunger** probably play a role.

Reason, Relevance and Attention

> Intelligence is not only the ability to reason; it is also the ability to find relevant material in memory and to deploy attention when needed.

Low exam scores

> He went on to study the characteristics of students who score very low on this test—the supervisory function of System 2 is weak in these people—and found that they are prone to answer questions with the first idea that comes to mind and **unwilling to invest the effort needed to check their intuitions**.

Bias and intelligence can co-exist

> Some people are better than others in these tasks of brain power—they are the individuals who excel in intelligence tests and are able to **switch from one task to another quickly and efficiently**. However, Stanovich argues that high intelligence **does not make people immune to biases**. Another ability is involved, which he labels rationality.

Brain and body are linked

> As cognitive scientists have emphasized in recent years, cognition is embodied; **you think with your body, not only with your brain**.

Cognitive ease and mood

> The various causes of ease or strain have interchangeable effects. When you are in a state of **cognitive ease, you are probably in a good mood**, like what you see, believe what you hear, trust your intuitions, and feel that the current situation is comfortably familiar.

Repetition and falsehoods

> Anything that makes it easier for the associative machine to run smoothly will also bias beliefs. **A reliable way to make people believe in falsehoods is frequent repetition**, because familiarity is not easily distinguished from truth. Authoritarian institutions and marketers have always known this fact.

Truth is sometimes just cognitive ease

> How do you know that a statement is true? If it is **strongly linked by logic or association to other beliefs or preferences you hold**, or comes from a source you trust and like, you will feel a sense of cognitive ease.

Examples of cognitive ease and correcting for a potential bias

> Speaking of Cognitive Ease “Let’s not dismiss their business plan just because the font makes it hard to read.” “We must be inclined to believe it because it has been repeated so often, but let’s think it through again.” “**Familiarity breeds liking.** This is a mere exposure effect.” “I’m in a very good mood today, and my System 2 is weaker than usual. I should be extra careful.”

When is jumping to conclusions ok and not ok?

> Jumping to conclusions is efficient if the **conclusions are likely to be correct** and the **costs of an occasional mistake acceptable**, and if the jump saves much time and effort. Jumping to conclusions is risky when the situation is unfamiliar, the **stakes are high, and there is no time to collect more information**.

Tendency to like everything about the person

> If you like the president’s politics, you probably like his voice and his appearance as well. The tendency to like (or dislike) **everything about a person—including things you have not observed**—is known as the **halo effect**.

Bias for speaking at first

> A simple rule can help: before an issue is discussed, all members of the committee should be asked to **write a very brief summary of their position**. This procedure makes good use of the value of the diversity of knowledge and opinion in the group. The **standard practice of open discussion gives too much weight to the opinions of those who speak early and assertively**, causing others to line up behind them.

Consistency vs completeness and Dunning Kruger

> It is the **consistency of the information that matters for a good story, not its completeness**. Indeed, you will often find that **knowing little makes it easier to fit everything you know into a coherent pattern**.

List of biases of judgment and choice:

- Overconfidence
- Framing effects
- Base-rate neglect

Substitution

> Substituting one question for another can be a good strategy for solving difficult problems, and George Pólya included substitution in his classic How to Solve It: **“If you can’t solve a problem, then there is an easier problem you can solve: find it.”**

Affect heuristic

> The psychologist Paul Slovic has proposed an affect heuristic in which **people let their likes and dislikes determine their beliefs about the world**. Your political preference determines the arguments that you find compelling. If you like the current health policy, you believe its benefits are substantial and its costs more manageable than the costs of alternatives.

Results depend on the method

> Like most research psychologists, I had routinely chosen samples that were too small and had often obtained results that made no sense. Now I knew why: the **odd results were actually artifacts of my research method**. My mistake was particularly embarrassing because I taught statistics and knew how to compute the sample size that would reduce the risk of failure to an acceptable level.

Media bias is caused by us

> The lesson is clear: estimates of causes of death are warped by media coverage. The coverage is itself biased toward novelty and poignancy. The **media do not just shape what the public is interested in, but also are shaped by it**. Editors cannot ignore the public’s demands that certain topics and viewpoints receive extensive coverage.

Availability cascade

> invented a name for the mechanism through which biases flow into policy: the availability cascade. They comment that in the social context, “all heuristics are equal, but availability is more equal than the others.”

How important is an idea?

> In particular, the importance of an idea is **often judged by the fluency (and emotional charge) with which that idea comes** to mind.

Why is terrorism more "dangerous" than traffic incidents?

> Even in countries that have been targets of intensive terror campaigns, such as Israel, the **weekly number of casualties almost never came close to the number of traffic deaths**. The difference is in the **availability of the two risks, the ease and the frequency with which they come to mind**. Gruesome images, endlessly repeated in the media, cause everyone to be on edge.

Policy makers should not ignore unfounded public fears...

> However, I also share Slovic’s belief that widespread fears, **even if they are unreasonable, should not be ignored by policy makers**. Rational or not, fear is painful and debilitating, and **policy makers must endeavor to protect the public from fear**, not only from real dangers.

Democracy and biases

> Democracy is inevitably messy, in part because the **availability and affect heuristics that guide citizens’ beliefs and attitudes are inevitably biased**, even if they generally point in the right direction. Psychology should inform the design of risk policies that combine the experts’ knowledge with the public’s emotions and intuitions.

Base rates of failures

> Some people **ignore base rates because they believe them to be irrelevant in the presence of individual information**. Others make the same mistake because they are not focused on the task.

Conjunction fallacy

> the idea of a conjunction fallacy, which people commit when they **judge a conjunction of two events to be more probable than one of the events** in a direct comparison.

Representativeness

> Representativeness belongs to a cluster of **closely related basic assessments that are likely to be generated together**. The most representative outcomes combine with the personality description to produce the most coherent stories. The most coherent stories are not necessarily the most probable, but they are plausible, and the **notions of coherence, plausibility, and probability are easily confused by the unwary**.

Raise doubts on strongest points and focus on weaknesses

> If you visit a courtroom you will observe that lawyers apply two styles of criticism: to demolish a case they raise doubts about the strongest arguments that favor it; to discredit a witness, they focus on the weakest part of the testimony. The **focus on weaknesses** is also normal in political debates.

Knowing a new fact vs understanding it

> People who are taught surprising statistical facts about human behavior may be impressed to the point of telling their friends about what they have heard, but this does not mean that their understanding of the world has really changed. The **test of learning psychology is whether your understanding of situations you encounter has changed, not whether you have learned a new fact**. There is a deep gap between our thinking about statistics and our thinking about individual cases.

Performance rewards

> was telling them about an important principle of skill training: **rewards for improved performance work better than punishment of mistakes**. This proposition is supported by much evidence from research on pigeons, rats, humans, and other animals.

Why does it seems sometimes that people do better immediately after getting shouted at? Regression to the mean

> What he had observed is known as regression to the mean, which in that **case was due to random fluctuations in the quality of performance**. Naturally, he **praised only a cadet whose performance was far better than average**. But the cadet was probably just lucky on that particular attempt and therefore likely to deteriorate regardless of whether or not he was praised. Similarly, the instructor would shout into a cadet’s earphones only when the **cadet’s performance was unusually bad and therefore likely to improve** regardless of what the instructor did.

Example of regression to the mean

> It was apparent that most (but not all) of **those who had done best the first time deteriorated on their second try, and those who had done poorly on the first attempt generally improved**. I pointed out to the instructors that what they saw on the board coincided with what we had heard about the performance of aerobatic maneuvers on successive attempts: poor performance was typically followed by improvement and good performance by deterioration, without any help from either praise or punishment.

When athletes' performance decrease it is erroneously attributed to over confidence instead

> Overconfidence and the pressure of meeting high expectations are often offered as explanations. But there is a simpler account of the jinx: an athlete who gets to be on the cover of Sports Illustrated must have **performed exceptionally well in the preceding season, probably with the assistance of a nudge from luck—and luck is fickle**.

Why we fail to understand regression to the mean

> Indeed, the statistician David Freedman used to say that if the topic of regression comes up in a criminal or civil trial, the side that must explain regression to the jury will lose the case. Why is it so hard? The main reason for the difficulty is a recurrent theme of this book: **our mind is strongly biased toward causal explanations and does not deal well with “mere statistics.”** When our attention is called to an event, associative memory will look for its cause—more precisely, activation will automatically spread to any cause that is already stored in memory.

Intuition

> Some intuitions draw primarily on **skill and expertise acquired by repeated experience**. The rapid and automatic judgments and choices of chess masters, fireground commanders, and physicians that Gary Klein has described in Sources of Power and elsewhere illustrate these skilled intuitions, in which **a solution to the current problem comes to mind quickly because familiar cues are recognized**.

Disappointed on early success

> Similarly, if you use childhood achievements to predict grades in college without regressing your predictions toward the mean, **you will more often than not be disappointed by the academic outcomes of early readers** and happily surprised by the grades of those who learned to read relatively late.

Not all errors are the same

> But there are situations in which **one type of error is much worse than another**. When a venture capitalist looks for “the next big thing,” the **risk of missing the next Google or Facebook is far more important than the risk of making a modest investment in a start-up that ultimately fails**.

Overconfidence

> And it is **natural for System 1 to generate overconfident judgments**, because confidence, as we have seen, is **determined by the coherence of the best story you can tell from the evidence at hand**. Be warned: **your intuitions will deliver predictions that are too extreme** and you will be inclined to put far too much faith in them.

Narrative fallacies

> Narrative fallacies arise inevitably from our continuous attempt to make sense of the world. The **explanatory stories that people find compelling are simple**; are concrete rather than abstract; **assign a larger role to talent, stupidity, and intentions than to luck**; and **focus on a few striking events that happened** rather than on the countless events that failed to happen.

Halo effect

> we think a baseball pitcher is handsome and athletic, for example, we are likely to rate him better at throwing the ball, too. Halos can also be negative: if we think a player is ugly, we will probably underrate his athletic ability. The halo effect **helps keep explanatory narratives simple and coherent** by exaggerating the consistency of evaluations: **good people do only good things and bad people are all bad**. The statement “Hitler loved dogs and little children” is shocking no matter how many times you hear it,

Luck vs skill

> The skilled rafter has gone down rapids hundreds of times. He has learned to read the roiling water in front of him and to anticipate obstacles. He has learned to make the tiny adjustments of posture that keep him upright. There are fewer opportunities for young men to learn how to create a giant company, and fewer chances to avoid hidden rocks—such as a brilliant innovation by a competing firm. Of course there was a great deal of skill in the Google story, but **luck played a more important role in the actual event than it does in the telling of it**. And the more luck was involved, the less there is to be learned.

Dunning Kruger and coherence

> Paradoxically, it is **easier to construct a coherent story when you know little**, when there are fewer pieces to fit into the puzzle. Our comforting conviction that the world makes sense rests on a secure foundation: our almost unlimited ability to ignore our ignorance.

Knowing the past and the future

> The core of the illusion is that **we believe we understand the past, which implies that the future also should be knowable**, but in fact we understand the past less than we believe we do. Know is not the only word that fosters this illusion.

Making sense

> The **mind that makes up narratives about the past is a sense-making organ**. When an unpredicted event occurs, we immediately adjust our view of the world to accommodate the surprise.

We cannot accurate reconstruct past beliefs

> Asked to reconstruct their former beliefs, people retrieve their current ones instead—an instance of substitution—and many cannot believe that they ever felt differently. **Your inability to reconstruct past beliefs will inevitably cause you to underestimate the extent to which you were surprised by past events.**

Outcome bias - hindsight is always 20/20

> We are prone to **blame decision makers for good decisions that worked out badly** and to give them **too little credit for successful moves that appear obvious only after the fact**. There is a clear **outcome bias**. When the outcomes are bad, the clients often blame their agents for not seeing the handwriting on the wall—forgetting that **it was written in invisible ink that became legible only afterward**.

When is hindsight bias greatest

> The **worse the consequence, the greater the hindsight bias**. In the case of a catastrophe, such as 9/11, we are especially ready to believe that the officials who failed to anticipate it were negligent or blind. On July 10, 2001, the Central Intelligence Agency obtained information that al-Qaeda might be planning a major attack against the United States.

Business books with biases: Luck plays a huge role

> The basic message of Built to Last and other similar books is that good managerial practices can be identified and that good practices will be rewarded by good results. Both messages are overstated. **The comparison of firms that have been more or less successful is to a significant extent a comparison between firms that have been more or less lucky.** Knowing the importance of luck, you should be particularly suspicious when highly consistent patterns emerge from the comparison of successful and less successful firms. **In the presence of randomness, regular patterns can only be mirages.**

Luck

> Because luck plays a large role, the **quality of leadership and management practices cannot be inferred reliably from observations of success.** And even if you had perfect foreknowledge that a CEO has brilliant vision and extraordinary competence, you still would be unable to predict how the company will perform with much better accuracy than the flip of a coin.

Coherence does not mean truth

> Confidence is a feeling, which reflects the coherence of the information and the cognitive ease of processing it. **It is wise to take admissions of uncertainty seriously**, but declarations of high confidence mainly tell you that an individual has **constructed a coherent story in his mind, not necessarily that the story is true**.

Traders are not skilled

> Nevertheless, the evidence from more than fifty years of research is conclusive: for a large majority of fund managers, the selection of stocks is more like rolling dice than like playing poker. Typically at least two out of every three mutual funds underperform the overall market in any given year.

Beware when success is due to luck and not actual skill

> Our message to the executives was that, at least when it came to building portfolios, the firm was rewarding luck as if it were skill. This should have been shocking news to them, but it was not.

Illusion of skill supported by culture of awards and promotions

> Finally, the **illusions of validity and skill are supported by a powerful professional culture**. We know that people can maintain an unshakable faith in any proposition, however absurd, when they are **sustained by a community of like-minded believers**.

Hindsight is 20/20 - we do not understand the past

> The **illusion that we understand the past** fosters overconfidence in our ability to predict the future.

Past is not created by a few people and it is pure luck

> We think that we should be able to explain the past by focusing on either large social movements and cultural and technological developments or the **intentions and abilities of a few great men**. The idea that **large historical events are determined by luck is profoundly shocking**, although it is demonstrably true.

Simplicity is better

> Why are experts inferior to algorithms? One reason, which Meehl suspected, is that experts try to be clever, think outside the box, and consider complex combinations of features in making their predictions. Complexity may work in the odd case, but more often than not it reduces validity. **Simple combinations of features are better.**

When a simple algorithm is fine...

> The important conclusion from this research is that an algorithm that is constructed on the back of an envelope is often good enough to compete with an optimally weighted formula, and certainly good enough to outdo expert judgment.

Simple Apgar's score in delivery rooms

> Applying Apgar’s score, the staff in delivery rooms finally had **consistent standards for determining which babies were in trouble**, and the formula is credited for an important contribution to reducing infant mortality. The Apgar test is still used every day in every delivery room.

Daniel Kahneman's design of Israel military admission

> By focusing on standardized, factual questions, I hoped to combat the halo effect, where favorable first impressions influence later judgments. As a further precaution against halos, I instructed the interviewers to go through the **six traits in a fixed sequence, rating each trait on a five-point scale** before going on to the next. And that was that. I informed the interviewers that they need not concern themselves with the recruit’s future adjustment to the military. Their only task was to **elicit relevant facts about his past** and to use that information to score each personality dimension.

Hiring metrics

> If you are serious about hiring the best possible person for the job, this is what you should do. First, **select a few traits that are prerequisites for success in this position** (technical proficiency, engaging personality, reliability, and so on). Don’t overdo it — six dimensions is a good number. The **traits you choose should be as independent as possible** from each other, and you should feel that you can assess them reliably by **asking a few factual questions**. Next, make a list of those questions for each trait and think about how you will score it, say on a 1–5 scale. You should have an idea of what you will call “very weak” or “very strong.”

Ease and coherence does not make it complete

> We are confident when the story we tell ourselves comes easily to mind, with no contradiction and no competing scenario. But **ease and coherence do not guarantee that a belief held with confidence is true**. The associative machine is set to suppress doubt and to evoke ideas and information that are compatible with the currently dominant story.

True expertise

> If subjective confidence is not to be trusted, how can we evaluate the probable validity of an intuitive judgment? When do judgments reflect true expertise? When do they display an illusion of validity? The answer comes from the two basic conditions for acquiring a skill: an **environment that is sufficiently regular to be predictable** an **opportunity to learn these regularities through prolonged practice**... When both these conditions are satisfied, **intuitions are likely to be skilled**.

The lucky ones where intuition is magic!

> Claims for correct intuitions in an unpredictable situation are self-delusional at best, sometimes worse. In the absence of valid cues, **intuitive “hits” are due either to luck or to lies**. If you find this conclusion surprising, you still have a lingering belief that intuition is magic. Remember this rule: **intuition cannot be trusted in the absence of stable regularities in the environment**.

Learning a skill

> The conditions for learning this skill are ideal, because you **receive immediate and unambiguous feedback every time you go around a bend**: the mild reward of a comfortable turn or the mild punishment of some difficulty in handling the car if you brake either too hard or not quite hard enough.

When to trust someone's intuitions?

> If the **environment is sufficiently regular** and if the judge has had a **chance to learn its regularities**, the associative machinery will recognize situations and **generate quick and accurate predictions and decisions**. You can trust someone’s intuitions if these conditions are met.

Planning fallacy

> overly optimistic forecasts of the outcome of projects are found everywhere. Amos and I coined the term planning fallacy to describe **plans and forecasts that are unrealistically close to best-case scenarios** could be improved by **consulting the statistics of similar cases**.

How planning fallacy harms the team

> When forecasting the outcomes of risky projects, executives too easily fall victim to the planning fallacy. In its grip, they **make decisions based on delusional optimism rather than on a rational weighting of gains, losses, and probabilities**. They **overestimate benefits and underestimate costs**. They spin scenarios of success while overlooking the potential for mistakes and miscalculations.

What happens with CEOs are anointed in the media

> The damage caused by overconfident CEOs is compounded when the business press anoints them as celebrities; the evidence indicates that **prestigious press awards to the CEO are costly to stockholders**. The authors write, “We find that firms with award-winning CEOs subsequently underperform, in terms both of stock and of operating performance. At the same time, CEO compensation increases, **CEOs spend more time on activities outside the company such as writing books and sitting on outside boards, and they are more likely to engage in earnings management**.”

Bias when planning

> We **focus on our goal, anchor on our plan**, and neglect relevant base rates, exposing ourselves to the planning fallacy. We focus on what we want to do and can do, neglecting the plans and skills of others. Both in explaining the past and in predicting the future, we focus on the causal role of skill and neglect the role of luck. We are therefore prone to an illusion of control. We focus on what we know and neglect what we do not know, which makes us **overly confident in our beliefs**.

Bias in outcomes

> To what extent will the outcome of your effort depend on what you do in your firm? This is evidently an easy question; the answer comes quickly and in my small sample it has never been less than 80%. Even when they are not sure they will succeed, **these bold people think their fate is almost entirely in their own hands**. They are surely wrong: the **outcome of a start-up depends as much on the achievements of its competitors and on changes in the market as on its own efforts**.

Pre-mortem

> The premise of the session is a short speech: “Imagine that we are **a year into the future**. We implemented the plan as it now exists. **The outcome was a disaster.** Please take **5 to 10 minutes to write a brief history of that disaster.**”

Advantages of a premortem

> The premortem has two main advantages: it **overcomes the groupthink** that affects many teams once a decision appears to have been made, and it **unleashes the imagination of knowledgeable individuals in a much-needed direction**.

Legitimising doubt

> The **suppression of doubt contributes to overconfidence** in a group where only supporters of the decision have a voice. The main virtue of the premortem is that it **legitimizes doubts**. Furthermore, it encourages even supporters of the decision to **search for possible threats** that they had not considered earlier.

Loss Aversion

> The third principle is loss aversion. When directly compared or weighted against each other, **losses loom larger than gains**. This asymmetry between the power of positive and negative expectations or experiences has an evolutionary history. **Organisms that treat threats as more urgent than opportunities have a better chance to survive and reproduce.**

Examples of loss aversion in both adults and kids

> The high price that Sellers set reflects the **reluctance to give up an object that they already own**, a reluctance that can be seen in babies who hold on fiercely to a toy and show great agitation when it is taken away. **Loss aversion is built into the automatic evaluations of System 1.**

How loss aversion also makes us focus more on crimes and war

> **Emotionally loaded words quickly attract attention**, and bad words (war, crime) attract attention faster than do happy words (peace, love). There is no real threat, but the mere reminder of a bad event is treated in System 1 as threatening.

Diminishing marginal utility

> The convex shape indicates **diminishing marginal utility**: the more leisure you have, the less you care for an extra day of it, and each added day is worth less than the one before. Similarly, the more income you have, the less you care for an extra dollar, and the amount you are willing to give up for an extra day of leisure increases.

Secret success of marriages

> They cite John Gottman, the well-known expert in marital relations, who observed that the long-term success of a relationship **depends far more on avoiding the negative than on seeking the positive**. Gottman estimated that a stable relationship requires that **good interactions outnumber bad interactions by at least 5 to 1**.

Small probabilities

> Furthermore, **people are almost completely insensitive to variations of risk among small probabilities**. A cancer risk of 0.001% is not easily distinguished from a risk of 0.00001%, although the former would translate to 3,000 cancers for the population of the United States, and the latter to 30.

Possibility effect

> When you pay attention to a threat, you worry—and the decision weights reflect how much you worry. Because of the possibility effect, the **worry is not proportional to the probability of the threat**. Reducing or mitigating the risk is not adequate; to eliminate the worry the probability must be brought down to zero.

Rare outcomes

> As expected from prospect theory, choice from description yields a possibility effect—**rare outcomes are overweighted relative to their probability**. In sharp contrast, overweighting is never observed in choice from experience, and underweighting is common.

How to tackle biases: internal metrics and external metrics

> Optimists believe that the decisions they make are more prudent than they really are, and loss-averse decision makers correctly reject marginal propositions that they might otherwise accept. There is no guarantee, of course, that the biases cancel out in every situation. An organization that could eliminate both excessive optimism and excessive loss aversion should do so. The **combination of the outside view with a risk policy should be the goal**.

Sunk cost

> All too often a company afflicted by sunk costs drives into the blizzard, throwing good money after bad **rather than accepting the humiliation of closing the account of a costly failure**. This situation is in the top-right cell of the fourfold pattern, where the choice is between a sure loss and an unfavorable gamble, which is often unwisely preferred.

How does replacing a CEO help?

> The members of the board do not necessarily believe that the new CEO is more competent than the one she replaces. **They do know that she does not carry the same mental accounts and is therefore better able to ignore the sunk costs** of past investments in evaluating current opportunities.

Sunk cost fallacy everyday

> The sunk-cost fallacy keeps people for **too long in poor jobs, unhappy marriages, and unpromising research projects**. I have often observed young scientists struggling to salvage a doomed project when they would be better advised to drop it and start a new one.

Forgo a discount vs pay a surcharge

> Their psychology was sound: people will more readily forgo a discount than pay a surcharge. The **two may be economically equivalent**, but they are **not emotionally equivalent**.

Framing effect

> An article published in 2003 noted that the rate of organ donation was close to 100% in Austria but only 12% in Germany, 86% in Sweden but only 4% in Denmark. These enormous differences are a framing effect, which is caused by the format of the critical question. The **high-donation countries have an opt out form**, where individuals who wish not to donate must check an appropriate box. Unless they take this simple action, they are considered willing donors. The **low-contribution countries have an opt-in form**: you must check a box to become a donor. That is all.

Memories are remembering self

> The **experiencing self** is the one that answers the question: “Does it hurt now?” The **remembering self** is the one that answers the question: “How was it, on the whole?” Memories are all we get to keep from our experience of living, and the **only perspective that we can adopt as we think about our lives is therefore that of the remembering self**.

We cannot trust our preferences

> The cold-hand study showed that **we cannot fully trust our preferences to reflect our interests**, even if they are based on personal experience, and even if the memory of that experience was laid down within the last quarter of an hour! **Tastes and decisions are shaped by memories, and the memories can be wrong.**

Intensity vs Duration

> An inconsistency is built into the design of our minds. We have strong preferences about the duration of our experiences of pain and pleasure. We want **pain to be brief** and **pleasure to last**. But our memory, a function of System 1, has evolved to **represent the most intense moment of an episode of pain or pleasure** (the peak) and the feelings when the episode was at its end. A memory that neglects duration will not serve our preference for long pleasure and short pains.

Duration neglect

> A story is about significant events and memorable moments, not about time passing. Duration neglect is normal in a story, and the ending often defines its character.

Peaks and Ends >> Duration

> However, the pattern did not change when the parents and older friends of students answered the same questions. In intuitive evaluation of entire lives as well as brief episodes, **peaks and ends matter but duration does not**.

Photography, memory and experience

> The photographer does not view the scene as a moment to be savored but as a future memory to be designed. Pictures may be useful to the remembering self—though we rarely look at them for very long, or as often as we expected, or even at all—but **picture taking is not necessarily the best way for the tourist’s experiencing self to enjoy a view**.

Peaks during short duration is more important than length of time

> The biggest surprise was the emotional experience of the time spent with one’s children, which for American women was **slightly less enjoyable than doing housework**. Here we found one of the few contrasts between French and American women: **Frenchwomen spend less time with their children but enjoy it more**, perhaps because they have more access to child care and spend less of the afternoon driving children to various activities.

Mindfulness and multi-tasking

> To get pleasure from eating, for example, you must notice that you are doing it. We found that French and American women spent about the same amount of time eating, but for Frenchwomen, eating was twice as likely to be focal as it was for American women. The Americans were far more prone to combine eating with other activities, and their pleasure from eating was correspondingly diluted.

Passive leisure to active leisure

> The feelings associated with different activities suggest that another way to **improve experience** is to switch time from passive leisure, such as TV watching, **to more active forms of leisure**, including socializing and exercise.

Focusing illusion

> This is the essence of the focusing illusion, which can be described in a single sentence: Nothing in life is as important as you think it is when you are thinking about it... The focusing illusion can **cause people to be wrong about their present state of well-being** as well as about the happiness of others, and about their own happiness in the future.

Exaggerate effect

> The focusing illusion (which Gilbert and Wilson call focalism) is a rich source of miswanting. In particular, it makes us prone to **exaggerate the effect of significant purchases or changed circumstances on our future well-being**.

Both must be considered

> The remembering self and the experiencing self must both be considered, because their interests do not always coincide. Philosophers could struggle with these questions for a long time.

Libertarian assumes that humans are rational

> The assumption that agents are rational provides the intellectual foundation for the libertarian approach to public policy: do not interfere with the individual’s right to choose, unless the choices harm others. Libertarian policies are further bolstered by admiration for the efficiency of markets in allocating goods to the people who are willing to pay the most for them.

Nudge

> The nudge is based on sound psychology, which I described earlier. The default option is naturally perceived as the normal choice. Deviating from the normal choice is an act of commission, which **requires more effortful deliberation**, takes on more responsibility, and is **more likely to evoke regret than doing nothing**. These are powerful forces that may guide the decision of someone who is otherwise unsure of what to do.

Nudge units

> Indeed, Britain’s government has created a new small unit whose mission is to apply the principles of behavioral science to help the government better accomplish its goals. The official name for this group is the Behavioural Insight Team, but it is known both in and out of government simply as the Nudge Unit.



> The **voice of reason may be much fainter than the loud and clear voice of an erroneous intuition**, and questioning your intuitions is unpleasant when you face the stress of a big decision. More doubt is the last thing you want when you are in trouble. The upshot is that it is much easier to identify a minefield when you observe others wandering into it than when you are about to do so. **Observers are less cognitively busy and more open to information than actors**.

Value of an organization

> Organizations are better than individuals when it comes to avoiding errors, because they naturally think more slowly and have the **power to impose orderly procedures**. Organizations can institute and enforce the **application of useful checklists**, as well as more elaborate exercises, such as **reference-class forecasting** and the **premortem**. At least in part by providing a distinctive vocabulary, organizations can also **encourage a culture in which people watch out for one another** as they approach minefields.

phenomenon anchoring

> The initial value, or starting point, may be suggested by the formulation of the problem, or it may be the result of a partial computation. In either case, adjustments are typically insufficient. That is, **different starting points yield different estimates**, which are biased toward the initial values. We call this phenomenon anchoring.
