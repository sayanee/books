---
layout: post
title:  "The Design of Everyday Things"
authors: Don Norman
categories:
- books
---

Good design in invisible

> Good design is actually a lot harder to notice than poor design, in part because good designs fit our needs so well that the design is invisible, serving us without drawing attention to itself.

Affordances and Signifiers

> Affordances define **what actions are possible**. Signifiers specify **how people discover those possibilities**: signifiers are signs, perceptible signals of what can be done.

Forcing actions

> The elaboration of forcing functions into two kinds: lock-in and lockout.

Radical innovation is rare

> Everyone wants radical innovation, but the truth is, most radical innovations fail, and even when they do succeed, it can take multiple decades before they are accepted. **Radical innovation, therefore, is relatively rare: incremental innovation is common**.

Discoverability and understanding

> With complex devices, discoverability and understanding require the aid of manuals or personal instruction. We accept this if the device is indeed complex, but it should be unnecessary for simple things. Many products defy understanding simply because they have too many functions and controls.

Non-physical structures need design too

> Not all designed things involve physical structures. **Services, lectures, rules and procedures**, and the organizational structures of businesses and governments do not have physical mechanisms, but their rules of operation have to be designed, sometimes informally, sometimes precisely recorded and specified.

Areas of Design

> The major areas of design relevant to this book are **industrial design, interaction design, and experience design**... industrial designers emphasizing **form and material**, interactive designers emphasizing **understandability and usability**, and experience designers emphasizing the **emotional impact**.

Operators are blamed

> When people fail to follow these bizarre, secret rules, and the machine does the wrong thing, its operators are **blamed for not understanding the machine, for not following its rigid specifications**.

Who's fault?

> It is the **machine and its design that are at fault**. It is the duty of machines and those who design them to understand people. It is not our duty to understand the arbitrary, meaningless dictates of machines.

If only read instructions!

> Engineers, moreover, make the mistake of thinking that logical explanation is sufficient: “**If only people would read the instructions**,” they say, “everything would be all right.”

Designing for people!

> The moral was simple: we were designing things for people, so we needed to understand both technology and people. But that's a difficult step for many engineers: machines are so logical, so orderly... we must **design our machines on the assumption that people will make errors**

HCD

> The solution is human-centered design (HCD), an approach that **puts human needs, capabilities, and behavior first**, then designs to accommodate those needs, capabilities, and ways of behaving.

Collaboration of device and person

> machine highlights the problems, then the person understands the issue, takes the proper actions, and the problem is solved. When this happens smoothly, the collaboration of person and device feels wonderful.

Experience is remembered

> Experience is critical, for it determines how fondly people remember their interactions.

Psychological concepts

> Discoverability results from appropriate application of five fundamental psychological concepts covered in the next few chapters: **affordances, signifiers, constraints, mappings, and feedback**.

Explaining == poor design

> Whenever you see hand-lettered signs pasted on doors, switches, or products, trying to explain how to work them, what to do and what not to do, you are also looking at poor design.

Mapping

> Mapping is an important concept in the design and layout of controls and displays. When the mapping **uses spatial correspondence between the layout of the controls and the devices** being controlled, it is easy to determine how to use them.

Feedback

> Feedback must be **immediate: even a delay of a tenth of a second can be disconcerting**. If the delay is too long, people often give up, going off to do other activities.

Poor feedback

> Poor feedback can be worse than no feedback at all, because it is distracting, uninformative, and in many cases irritating and anxiety-provoking.

Ignoring when too many

> Too many announcements cause people to ignore all of them, or wherever possible, disable all of them, which means that critical and important ones are apt to be missed.

Continual beeps and alarms can be harmful!

> The continual beeps and alarms of equipment can be dangerous. In many emergencies, workers have to **spend valuable time turning off all the alarms because the sounds interfere with the concentration** required to solve the problem.

Challenges of design

> Designing well is not easy. The manufacturer wants something that can be **produced economically**. The store wants something that will be **attractive to its customers**. The purchaser has several demands. In the store, the purchaser focuses on **price and appearance**, and perhaps on prestige value. At home, the same person will pay more attention to **functionality and usability**. The repair service cares about **maintainability**: how easy is the device to take apart, diagnose, and service? The needs of those concerned are different and often conflict.

Human action

> 1. Goal (form the goal) 2. Plan (the action) 3. Specify (an action sequence) 4. Perform (the action sequence) 5. Perceive (the state of the world) 6. Interpret (the perception) 7. Compare (the outcome with the goal) The seven-stage action cycle is simplified, but it provides a useful framework for understanding human action and for guiding design.

Emotions --> Thoughts

> We also tend to believe that thought can be separated from emotion. This is also false. Cognition and emotion cannot be separated. Cognitive thoughts lead to emotions: **emotions drive cognitive thoughts**.

Subconscious

> Because **much human behavior is subconscious that is, it occurs without conscious awareness we often don't know what we are about to do, say, or think until after we have done it**. It's as if we had two minds: the subconscious and the conscious, which don't always talk to each other.

Pattern matching

> Subconscious thought matches patterns, finding the best possible match of one's past experience to the current one. It proceeds rapidly and automatically, without effort. Subconscious processing is one of our strengths.

Precursors

> Most scientists do not call these emotions: they are precursors to emotion. **Stand at the edge of a cliff and you will experience a visceral response**.

Reflective

> The highest levels of emotions come from the reflective level, for it is here that causes are assigned and where **predictions of the future take place**.

Emotions

> Most products do not cause fear, running, or fleeing, but **badly designed devices can induce frustration and anger, a feeling of helplessness and despair, and possibly even hate**. Well-designed devices can **induce pride and enjoyment, a feeling of being in control and pleasure** possibly even love and attachment.

Immersive experience

> The constant tension coupled with continual progress and success can be an engaging, immersive experience sometimes lasting for hours.

Panic bars during emergencies

> the law requires doors in public places to open outward, and moreover to be operated by so-called panic bars, so that they automatically open when people, in a panic to escape a fire, push their bodies against them. This is a great application of appropriate affordances

Feedback for progress

> Modern systems try hard to provide feedback within 0.1 second of any operation, to reassure the user that the request was received. This is especially important if the operation will take considerable time. The presence of a filling hourglass or rotating clock hands is a reassuring sign that work is in progress.

Delay with time estimates

> When the delay can be predicted, some systems provide time estimates as well as progress bars to indicate how far along the task has gone.

Failure and self-blame

> The result: mathematics phobia not because the material is difficult, but because it is taught so that difficulty in one stage hinders further progress. The problem is that once failure starts, it is soon generalized by self-blame to all of mathematics.

Failure

> If designers and researchers do not sometimes fail, it is a sign that they are not trying hard enough **they are not thinking the great creative thoughts** that will provide breakthroughs in how we do things. It is **possible to avoid failure, to always be safe**.

So, to the designers who are reading this, let me give some advice:

- Do not blame people when they fail to use your products properly.
- Take people's difficulties as signifiers of where the product can be improved.
- Eliminate all error messages from electronic or computer systems.
- Make it possible to correct problems directly from help and guidance messages.
- Assume that what people have done is partially correct
- Think positively, for yourself and for the people you interact with.

System error or user error?

> when the system stopped working or did something strange, they dutifully reported it as a problem. But when they made the Return versus Enter error, they blamed themselves. After all, they had been told what to do. They had simply erred.

Blaming and "Human error"

> When major accidents occur, **official courts of inquiry are set up to assess the blame**. More and more often the blame is **attributed to “human error.”** The person involved can be fined, punished, or fired. Maybe training procedures are revised. The law rests comfortably. But in my experience, **human error usually is a result of poor design: it should be called system error**. Humans err continually; it is an intrinsic part of our nature. System design should take this into account.

No more "Human error"

> But designers should take special pains to make errors as cost-free as possible. Here is my credo about errors: **Eliminate the term human error**. Instead, talk about communication and interaction: what we call an error is usually bad communication or interaction.

Design to take in human inputs

> Today, we insist that people perform abnormally, to adapt themselves to the **peculiar demands** of machines, which includes always **giving precise, accurate information**. Humans are particularly bad at this, yet when they fail to meet the arbitrary, inhuman requirements of machines, we call it human error. No, it is design error.

Machines vs People

> Our strengths are in our flexibility and creativity, in coming up with solutions to novel problems. We are **creative and imaginative, not mechanical and precise**. Machines require precision and accuracy; people don't.

Human inputs are...

> And we are particularly **bad at providing precise and accurate inputs**. So why are we always required to do so? Why do we put the requirements of machines above those of people?

Accommodate all types of input - design it once and cover all

> Why not figure out the variety of ways a person might fill out a form and accommodate all of them? Some companies have done excellent jobs at this, so let us celebrate their actions.

Feed info

> The information that **helps answer questions of execution** (doing) is feedforward. The information that aids in **understanding what has happened** is feedback.

1. Discoverability
2. Feedback
3. Conceptual model
4. Affordances
5. Signifiers
6. Mappings

Examine well designed products

> next time you come across a well-designed object, one that you can use smoothly and effortlessly on the first try, stop and examine it.

Complex outcomes

> Consider this as an example of design principles interacting with the messy practicality of the real world. What appears good in principle can sometimes fail when introduced to the world. Sometimes, bad products succeed and good products fail. The world is complex.

Using constraints

> The constraints by themselves are often not sufficient to determine the proper reassembly of the device mistakes do get made but the **constraints reduce the amount that must be learned to a reasonable quantity**.

Password

> They understand crime, but not human behavior. They believe that “strong” passwords, ones difficult to guess, are required, and that they must be changed frequently. They do not seem to recognize that we now need so many passwords even easy ones that it is difficult to remember which goes with which requirement. This creates a new layer of vulnerability. The **more complex the password requirements, the less secure the system**. Why? Because people, unable to remember all these combinations, write them down.

Multiple Identifiers

> The safest methods require multiple identifiers, the most common schemes requiring at least two different kinds: **“something you have” plus “something you know.”** The “something you have” is often a physical identifier, such as a card or key, perhaps even something implanted under the skin or a biometric identifier, such as fingerprints or patterns of the eye's iris. The “something you know” would be knowledge in the head, most likely something memorized.

Problem with eye witness

> This is one reason that eyewitness testimony in courts of law is so problematic: eyewitnesses are notoriously unreliable. A huge number of psychological experiments show **how easy it is to implant false memories into people's minds** so convincingly that people refuse to admit that the memory is of an event that never happened.

Approximate

> Approximate answers are often good enough, even if technically wrong.

Estimates are good most of the time

> It is rare that we need to know the answers to complex arithmetic problems with great precision: **almost always, a rough estimate is good enough**. When precision is required, use a calculator. That's what machines are good for: providing great precision. For most purposes, estimates are good enough.

Machine and people's focus are different

> Machines should focus on solving arithmetic problems. People should focus on higher-level issues, such as the reason the answer was needed.

Scientific method

> Science strives for truth. As a result, scientists are **always debating, arguing, and disagreeing** with one another. The scientific method is one of **debate and conflict**.

Helping with memory error

> The design implication? The easier it is to enter the information into the relevant equipment as it is heard, the **less chance of memory error**. The air-traffic control system is evolving to help. The instructions from the air-traffic controllers will be sent digitally, so that they can remain displayed on a screen as long as the pilot wishes.

Signal + Message

> The famous “tie a string around your finger” reminder provides only the signal. It gives no hint of what is to be remembered. Writing a note to yourself provides only the message; it doesn't remind you ever to look at it. The ideal reminder has to have both components: the **signal that something is to be remembered, and then the message of what it is**.

Types of reminders

> But if the reminder comes at the correct time or location, the environmental cue can suffice to provide enough knowledge to aid retrieval of the to-be-remembered item. **Time-based reminders** can be effective: the bing of my cell phone reminds me of the next appointment. **Location-based reminders** can be effective in giving the cue at the precise place where it will be needed.

Type of mappings:

1. Best mapping: Controls are mounted directly on the item to be controlled
- Second-best mapping: Controls are as close as possible to the object to be controlled
- Third-best mapping: Controls are arranged in the same spatial configuration as the objects to be controlled.

Good mappings require little

> Sometimes there are labels. But the proper natural mapping requires **no diagrams, no labels, and no instructions**

Cultural indications

> I discovered that they, too, were split in their opinions: some people firmly believe that it is the top button and some, just as firmly, believe it is the bottom button. Everyone is surprised to learn that someone else might think differently. I was puzzled until I realized that this was a point-of-view problem, very similar to the way different cultures view time. In some cultures, time is represented mentally as if it were a road stretching out ahead of the person.

Legacy

> Why does inelegant design persist for so long? This is called the legacy problem, and it will come up several times in this book. Too **many devices use the existing standard that is the legacy**.

Pushing the boundaries and changing perceptions

> But just as cultural constraints can change with time, so, too, can semantic ones. Extreme sports push the boundaries of what we think of as meaningful and sensible. New technologies change the meanings of things. And creative people continually change how we interact with our technologies and one another.

Activity-centered >> Device-centered

> A related but wrong approach is to be device-centered rather than activity-centered. When they are device-centered, different control screens cover lights, sound, computer, and video projection. This requires the lecturer to go to one screen to adjust the light, a different screen to adjust sound levels, and yet a different screen to advance or control the images. It is a **horrible cognitive interruption to the flow of the talk**

One location

> Activity-centered controls anticipate this need and **put light, sound level, and projection controls all in one location**.

Safety engineering

> In the field of safety engineering, forcing functions show up under other names, in particular as specialized methods for the prevention of accidents. Three such methods are **interlocks, lock-ins, and lockouts**.

Interlock

> An interlock forces operations to take place in proper sequence. Microwave ovens and devices with interior exposure to high voltage use interlocks as forcing functions to **prevent people from opening the door of the oven or disassembling the devices without first turning off the electric power**: the interlock disconnects the power the instant the door is opened or the back is removed.

Balance

> Forcing functions can be a nuisance in normal usage. The result is that many people will deliberately disable the forcing function, thereby negating its safety feature. The clever designer has to **minimize the nuisance value while retaining the safety feature of the forcing function** that guards against the occasional tragedy.

Change is hard

> People invariably object and complain whenever a new approach is introduced into an existing array of products and systems. Conventions are violated: new learning is required. The merits of the new system are irrelevant: it is the change that is upsetting.

Legacy systems

> The metric scale of measurement is superior to the English scale of units in almost every dimension: it is logical, easy to learn, and easy to use in computations. Today, over two centuries have passed since the metric system was developed by the French in the 1790s, yet three countries still resist its use: the United States, Liberia, and Myanmar.

Consistency vs changes

> Consistency in design is virtuous. It means that lessons learned with one system transfer readily to others. On the whole, consistency is to be followed. If a new way of doing things is only slightly better than the old, it is better to be consistent. But if there is to be a change, everybody has to change. Mixed systems are confusing to everyone. When a new way of doing things is vastly superior to another, then the merits of change outweigh the difficulty of change. Just because something is different does not mean it is bad. If we only kept to the old, we could never improve.

Sound

> Sound is tricky. It can annoy and distract as easily as it can aid. Sounds that at one's first encounter are pleasant or cute easily become annoying rather than useful. One of the virtues of sounds is that they can be detected even when attention is applied elsewhere.

Skeuomorphic

> Skeuomorphic is the technical term for incorporating old, familiar ideas into new technologies, even though they no longer play a functional role. Skeuomorphic designs are often comfortable for traditionalists, and indeed the history of technology shows that new technologies and materials often slavishly **imitate the old for no apparent reason except that is what people know how to do**. Early automobiles looked like horse-driven carriages without the horses (which is also why they were called horseless carriages); early plastics were designed to look like wood; folders in computer file systems often look the same as paper folders, complete with tabs.

Boring with fast response or multi-tasking for people is bad

> We put people in boring environments with nothing to do for hours on end, until suddenly they must respond quickly and accurately. Or we subject them to complex, high-workload environments, where they are continually interrupted while having to do multiple tasks simultaneously. Then we wonder why there is failure.

People are found guilty :( - does not work

> When an error causes a financial loss or, worse, leads to an injury or death, a special committee is convened to investigate the cause and, almost without fail, guilty people are found. The next step is to **blame and punish them with a monetary fine**, or by firing or jailing them. Sometimes a lesser punishment is proclaimed: make the guilty parties go through more training. Blame and punish; **blame and train**.

Change the system

> When people err, **change the system so that type of error will be reduced or eliminated**. When complete elimination is not possible, redesign to reduce the impact.

People vs machines

> People are **creative, constructive, exploratory**) beings. We are particularly good at novelty, at creating new ways of doing things, and at seeing new opportunities. **Dull, repetitive, precise requirements** fight against these traits. We are alert to changes in the environment, noticing new things, and then thinking about them and their implications. These are virtues, but they get turned into negative features when we are forced to serve machines.

Slips vs mistakes

> paradoxically, they tend to occur more frequently to skilled people than to novices. Why? Because slips often result from a lack of attention to the task. Skilled people experts tend to perform tasks automatically, under subconscious control. Novices have to pay considerable conscious attention, resulting in a relatively low occurrence of slips.

Description-similarity error

> A lineup of identical-looking switches or displays is very apt to lead to **description-similarity error**. In the design of airplane cockpits, many controls are **shape coded so that they both look and feel different** from one another:

Mitigating memory-lapse errors

> There are several ways to combat memory-lapse errors. One is to minimize the number of steps; another, to provide vivid reminders of steps that need to be completed. A superior method is to use the forcing function

Recent and frequent

> Recent events are remembered far better than less recent ones. Frequent events are remembered through their regularities, and unique events are remembered because of their uniqueness.

Hindsight and foresight

> Hindsight is always superior to foresight. When the accident investigation committee reviews the event that contributed to the problem, they know what actually happened, so it is easy for them to pick out which information was relevant, which was not. This is retrospective decision making. But when the incident was taking place, the people were probably overwhelmed with far too much irrelevant information and probably not a lot of relevant information.

State of the system

> The design challenge is to present the information about the state of the system (a device, vehicle, plant, or activities being monitored) in a way that is easy to assimilate and interpret, as well as to provide alternative explanations and interpretations.

Social pressures

> Never underestimate the power of social pressures on behavior, causing otherwise sensible people to do things they know are wrong and possibly dangerous.

Reward >> Pressures

> How can we overcome these kinds of social problems? Good design alone is not sufficient. We need different training; we need to reward safety and put it above economic pressures. It helps if the equipment can make the potential dangers visible and explicit, but this is not always possible. To adequately address social, economic, and cultural pressures and to improve upon company policies are the hardest parts of ensuring safe operation and behavior.

Electronic checklist >> Human checklist

> In general, it is bad design to impose a sequential structure to task execution unless the task itself requires it. This is one of the major benefits of **electronic checklists: they can keep track of skipped items and can ensure that the list will not be marked as complete until all items have been done**.

Designing when things go wrong

> It is relatively easy to design for the situation where everything goes well, where people use the device in the way that was intended, and no unforeseen events occur. The tricky part is to design for when things go wrong.

One single error cannot cause widespread damage

> Many systems compound the problem by making it easy to err but difficult or impossible to discover error or to recover from it. It should not be possible for one simple error to cause widespread damage.

Undo

> Perhaps the most powerful tool to minimize the impact of errors is the Undo command in modern electronic systems, reversing the operations performed by the previous command, wherever possible.

Delete vs Trash

> not only is Undo a standard command, but when files are “deleted,” they are actually simply moved from sight and stored in the file folder named “Trash,” so that in the above example, the person could open the Trash and retrieve the erroneously deleted file.

Simple explanations are not the case

> This is why the attempt to find “the” cause of an accident is usually doomed to fail. Accident investigators, the press, government officials, and the everyday citizen like to find simple explanations for the cause of an accident.

Restoring the system

> Sometimes the problems do not arise in the organization but outside it, such as when fierce storms, earthquakes, or tidal waves demolish large parts of the existing infrastructure. In either case, the question is **how to design and manage these systems so that they can restore services with a minimum of disruption and damage**.

Real >> Simulation

> Although it might seem dangerous to do this while the systems are online, serving real customers, the only way to test these large, complex systems is by doing so. Small tests and simulations do not carry the complexity, stress levels, and unexpected events that characterize real system failures.

Lowering injury

> Across the world, automobile accidents kill and injure tens of millions of people every year. When we finally have widespread adoption of self-driving cars, the accident and casualty rate will probably be dramatically reduced, just as automation in factories and aviation have increased efficiency while lowering both error and the rate of injury.

Action == Task + task + task

> An activity is a collected set of tasks, but all performed together toward a common high-level goal. A task is an organized, cohesive set of operations directed toward a single, low-level goal.

Whole

> Focusing upon tasks is too limiting. Apple's success with its music player, the iPod, was because Apple supported the entire activity involved in listening to music: **discovering it, purchasing it, getting it into the music player, developing playlists** (that could be shared), and listening to the music.

Design for activities not individuals

> Design for individuals and the results may be wonderful for the particular people they were designed for, but a mismatch for others. Design for activities and the result will be usable by everyone.

Product = Various activities

> Design must take into account sales and marketing, servicing and help desks, engineering and manufacturing, costs and schedules. That's why it's so challenging. That's why it's so much fun and rewarding when it all comes together to create a successful product.

Interest + Skills

> Design for interests and skill levels. Don't be trapped by overly general, inaccurate stereotypes.

Standardization is a challenge

> Even when all parties agree on the merits of standardization, the **task of selecting standards becomes a lengthy, politicized issue**. A small company can standardize its products without too much difficulty, but it is much more difficult for an industrial, national, or international body to agree to standards.

Long to establish standards

> Standards can take so long to be established that by the time they do come into wide practice, they can be irrelevant. Nonetheless, standards are necessary. They simplify our lives and make it possible for different brands of equipment to work together in harmony.

Pros and cons of Standardization

> Standardize and you simplify lives: everyone learns the system only once. But don't standardize too soon; you may be locked into a primitive technology, or you may have introduced rules that turn out to be grossly inefficient, even error-inducing. Standardize too late, and there may already be so many ways of doing things that no international standard can be agreed on.

Incremental > Radical

> When new technologies emerge, there is a temptation to develop new products immediately. But the time for radically new products to become successful is measured in years, decades, or in some instances centuries. This causes me to examine the two forms of product innovation relevant to design: incremental (less glamorous, but most common) and radical (most glamorous, but rarely successful).

Always delay and more costly

> Remember Norman's Law of Chapter 6 : The day a product development process starts, it is behind schedule and above budget.

Focus on strength

> Most companies compare features with their competition to determine where they are weak, so they can strengthen those areas. Wrong, argues Moon. A better strategy is to concentrate on areas where they are **stronger and to strengthen them even more**. Then focus all marketing and advertisements to point out the strong points.

Idea --> Product --> Process?

> How long does it take for an idea to become a product? And after that, how long before the product becomes a long-lasting success? Inventors and founders of startup companies like to think the interval from idea to success is a single process, with the total measured in months. In fact, it is **multiple processes, where the total time is measured in decades, sometimes centuries**.

Multitouch

> It took **almost three decades from the invention of multitouch before companies were able to manufacture the technology with the required robustness, versatility, and very low cost necessary** for the idea to be deployed in the home consumer market. **Ideas take a long time to traverse the distance from conception to successful product**.

Stigler's law

> Although the title of the drawing gives credit to Thomas Edison, he had nothing to do with this. This is sometimes called **Stigler's law: the names of famous people often get attached to ideas even though they had nothing to do with them**. The world of product design offers many examples of Stigler's law. Products are thought to be the invention of the company that most successfully capitalized upon the idea, not the company that originated it. In the world of products, original ideas are the easy part.

Readiness to take on

> Apple QuickTake. It failed. Probably you are unaware that Apple ever made cameras. It failed because the **technology was limited, the price high, and the world simply wasn't ready to dismiss film and chemical processing of photographs**.

Lab --> 1 product --> Widespread == 3/4 decades

> Every modern innovation, especially the ones that significantly change lives, takes multiple decades to move from concept to company success A **rule of thumb is twenty years from first demonstrations in research laboratories to commercial product, and then a decade or two from first commercial release to widespread adoption**.

Books are bad?

> These fears have long been with us. In ancient Greece, Plato tells us that Socrates complained about the impact of books, arguing that **reliance on written material would diminish not only memory but the very need to think, to debate, to learn through discussion**.

Human + Machines >> Humans / Machines

> No, on the contrary, it unleashes the mind from the petty tyranny of tending to the trivial and allows it to concentrate on the important and the critical. Reliance on technology is a benefit to humanity. **With technology, the brain gets neither better nor worse. Instead, it is the task that changes. Human plus machine is more powerful than either human or machine alone.**

Aided mind >> Unaided mind

> The power of the unaided mind is highly overrated. Without external aids, deep, sustained reasoning is difficult. Unaided memory, thought, and reasoning are all limited in power. Human intelligence is highly flexible and adaptive, superb at inventing procedures and objects that overcome its own limits. The real powers come from devising external aids that enhance cognitive abilities.
